# Orion - Enterprise RAG Platform

<div align="center">

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-00a393.svg)](https://fastapi.tiangolo.com/)
[![Tests](https://img.shields.io/badge/tests-116%20passed-brightgreen.svg)](https://github.com/Ralf090102/Orion)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

*A powerful, modular Retrieval-Augmented Generation (RAG) system with multi-user support, advanced document processing, and enterprise-grade architecture.*

</div>

## Key Features

### ğŸ—ï¸ **Modular Architecture**
- **Core RAG Engine**: Sophisticated document processing and retrieval
- **FastAPI Backend**: RESTful API with async processing
- **System Tray Service**: Background document monitoring
- **Desktop Integration**: Cross-platform desktop application (Tauri)
- **Multi-User Support**: Isolated workspaces for different users

### ğŸ“„ **Advanced Document Processing**
- **Multi-Format Support**: PDF, DOCX, Excel, TXT, CSV, MD, RTF, and more
- **OCR Integration**: Extract text from images using EasyOCR/Tesseract
- **Table Extraction**: Advanced PDF table processing with Camelot/Tabula
- **Media Intelligence**: Smart image and document analysis
- **Incremental Updates**: Only process changed documents

### ğŸ§  **Intelligent Query Processing**
- **Query Enhancement**: HyDE, query expansion, and decomposition
- **Context-Aware Retrieval**: Smart document ranking and re-ranking
- **Conversation Memory**: Persistent chat sessions with context
- **Multi-Query Processing**: Parallel query execution for better results

### âš¡ **Performance & Scalability**
- **Async Processing**: High-performance document ingestion
- **Smart Caching**: LRU caching for embeddings and queries  
- **Background Processing**: Non-blocking document updates
- **Resource Management**: Efficient memory and CPU utilization

## ğŸš€ Quick Start

### Prerequisites

1. **Install Ollama**: Download from [ollama.ai](https://ollama.ai)
2. **Install Required Models**:
   ```bash
   ollama pull mistral:latest
   ollama pull nomic-embed-text:latest
   ```

### Installation

```bash
# Clone the repository
git clone https://github.com/Ralf090102/Orion.git
cd Orion

# Create virtual environment (recommended)
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .
```

### Usage Options

#### ğŸ–¥ï¸ **CLI Interface** (Legacy)
```bash
# Interactive mode with enhanced features
python run.py

# Or use the new modular CLI
python run_new.py --mode cli
```

#### ğŸŒ **Web API**
```bash
# Start FastAPI backend server
python run_new.py --mode backend

# Access API documentation at: http://localhost:8000/docs
```

#### ğŸ“± **System Tray Service**
```bash
# Run as background service with system tray
python run_new.py --mode tray
```

#### ğŸ–±ï¸ **Desktop Application**
```bash
# Launch cross-platform desktop app
python run_new.py --mode desktop
```

## ï¿½ API Documentation

### REST API Endpoints

Once the backend is running (`python run_new.py --mode backend`), you can access:

- **ğŸ“– Interactive Docs**: http://localhost:8000/docs
- **ğŸ“‹ OpenAPI Schema**: http://localhost:8000/openapi.json

### Core Endpoints

#### ğŸ“¥ Document Ingestion
```http
POST /api/v1/ingest
Content-Type: multipart/form-data

{
  "files": [<file1>, <file2>, ...],
  "user_id": "user123",
  "options": {
    "chunk_size": 1000,
    "chunk_overlap": 200,
    "use_async": true
  }
}
```

#### ğŸ’¬ Query Processing
```http
POST /api/v1/query
Content-Type: application/json

{
  "question": "What are the main findings?",
  "user_id": "user123",
  "options": {
    "use_enhancement": true,
    "retrieval_k": 5,
    "model": "mistral:latest"
  }
}
```

#### ğŸ“Š System Status
```http
GET /api/v1/system/health
GET /api/v1/system/stats
GET /api/v1/system/models
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# Core Settings
export ORION_EMBEDDING_MODEL="nomic-embed-text:latest"
export ORION_LLM_MODEL="mistral:latest" 
export ORION_OLLAMA_BASE_URL="http://localhost:11434"

# Performance Settings
export ORION_CHUNK_SIZE=1000
export ORION_CHUNK_OVERLAP=200
export ORION_RETRIEVAL_K=5
export ORION_TEMPERATURE=0.7

# Advanced Features
export ORION_ENABLE_OCR=true
export ORION_ENABLE_TABLE_EXTRACTION=true
export ORION_ASYNC_PROCESSING=true
export ORION_CACHE_SIZE=1000

# Multi-User Settings
export ORION_DEFAULT_USER_ID="default"
export ORION_PERSIST_PATH="./vectorstore"
```

### Advanced Configuration

Create a custom `config.yaml`:

```yaml
# Core RAG Settings
rag:
  chunk_size: 1000
  chunk_overlap: 200
  retrieval_k: 5
  temperature: 0.7

# Model Settings  
models:
  embedding: "nomic-embed-text:latest"
  llm: "mistral:latest"
  ollama_url: "http://localhost:11434"

# Processing Features
features:
  ocr_enabled: true
  table_extraction: true
  async_processing: true
  query_enhancement: true

# Performance
performance:
  cache_size: 1000
  max_workers: 4
  timeout_seconds: 300

# Storage
storage:
  base_path: "./vectorstore"
  backup_enabled: true
  compression: true
```

## ğŸ—ï¸ Architecture

### Modular Design

```mermaid
graph TB
    subgraph "User Interfaces"
        CLI[CLI Interface]
        Web[Web Interface]
        Desktop[Desktop App]
        Tray[System Tray]
    end
    
    subgraph "Backend Services"
        API[FastAPI Backend]
        Service[Background Service]
    end
    
    subgraph "Core Engine"
        RAG[RAG Pipeline]
        Processing[Document Processing]
        Intelligence[AI Intelligence]
    end
    
    subgraph "Storage & External"
        Vector[Vector Store]
        Memory[Conversation Memory]
        Ollama[Ollama LLMs]
        Files[Document Files]
    end
    
    CLI --> API
    Web --> API
    Desktop --> API
    Tray --> Service
    
    API --> RAG
    Service --> RAG
    
    RAG --> Processing
    RAG --> Intelligence
    
    Processing --> Vector
    Intelligence --> Memory
    RAG --> Ollama
    Processing --> Files
```

### Directory Structure

```
Orion/
â”œâ”€â”€ ğŸ  Root Configuration
â”‚   â”œâ”€â”€ pyproject.toml          # Project configuration
â”‚   â”œâ”€â”€ requirements.txt        # Dependencies
â”‚   â””â”€â”€ run_new.py             # Multi-mode launcher
â”‚
â”œâ”€â”€ ğŸ§  core/                   # Core RAG Engine
â”‚   â”œâ”€â”€ rag/                   # RAG Components
â”‚   â”‚   â”œâ”€â”€ ingest.py          # Document ingestion
â”‚   â”‚   â”œâ”€â”€ query.py           # Query processing  
â”‚   â”‚   â”œâ”€â”€ llm.py            # LLM integration
â”‚   â”‚   â”œâ”€â”€ chat.py           # Chat sessions
â”‚   â”‚   â””â”€â”€ ...               # Query enhancement, memory
â”‚   â”œâ”€â”€ processing/            # Document Processing
â”‚   â”‚   â”œâ”€â”€ chunking.py       # Smart chunking
â”‚   â”‚   â”œâ”€â”€ media_processing.py # OCR & tables
â”‚   â”‚   â””â”€â”€ document_intelligence.py # AI analysis
â”‚   â””â”€â”€ utils/                 # Utilities
â”‚       â”œâ”€â”€ config.py         # Configuration
â”‚       â”œâ”€â”€ orion_utils.py    # Core utilities
â”‚       â””â”€â”€ caching.py        # Smart caching
â”‚
â”œâ”€â”€ ğŸŒ backend/               # FastAPI Backend
â”‚   â”œâ”€â”€ api/                  # REST Endpoints
â”‚   â”‚   â”œâ”€â”€ ingest.py         # Ingestion API
â”‚   â”‚   â”œâ”€â”€ query.py          # Query API
â”‚   â”‚   â””â”€â”€ system.py         # System API
â”‚   â”œâ”€â”€ services/             # Business Logic
â”‚   â””â”€â”€ main.py              # FastAPI app
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ frontend/              # Svelte Frontend
â”‚   â”œâ”€â”€ src/                  # Svelte components
â”‚   â””â”€â”€ public/              # Static assets
â”‚
â”œâ”€â”€ ğŸ“± system_tray/           # Background Service
â”‚   â””â”€â”€ service.py           # System tray integration
â”‚
â”œâ”€â”€ ğŸ–±ï¸ desktop/               # Tauri Desktop App
â”‚   â”œâ”€â”€ src-tauri/           # Rust backend
â”‚   â””â”€â”€ src/                 # Web frontend
â”‚
â””â”€â”€ ğŸ§ª tests/                # Comprehensive Tests
    â”œâ”€â”€ test_*.py           # Unit tests
    â””â”€â”€ conftest.py         # Test configuration
```

## ğŸ§ª Testing & Development

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=core --cov=backend

# Run specific test categories
pytest -m unit          # Unit tests only
pytest -m integration   # Integration tests only
pytest -m "not slow"    # Exclude slow tests

# Run with detailed output
pytest -v --tb=short
```

### Development Setup

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install

# Run code formatting
black core/ backend/ tests/
ruff check --fix core/ backend/ tests/

# Type checking
mypy core/ backend/
```

### Code Quality

This project maintains high code quality standards:

- **ğŸ”§ Black**: Code formatting
- **âš¡ Ruff**: Fast Python linter
- **ğŸ” MyPy**: Static type checking
- **ğŸ§ª Pytest**: Comprehensive test suite (116+ tests)
- **ğŸ“Š Coverage**: Code coverage tracking

## ğŸ› ï¸ Supported Features

### ğŸ“„ Document Types

| Format | Extension | Features |
|--------|-----------|----------|
| **PDF** | `.pdf` | âœ… Text extraction, âœ… OCR, âœ… Table extraction |
| **Word** | `.docx` | âœ… Full document parsing, âœ… Metadata |
| **Excel** | `.xlsx`, `.xls` | âœ… Multi-sheet support, âœ… Formulas |
| **Text** | `.txt`, `.md`, `.rtf` | âœ… Plain text, âœ… Markdown parsing |
| **Images** | `.jpg`, `.png`, `.tiff` | âœ… OCR text extraction |
| **CSV** | `.csv` | âœ… Structured data processing |

### ğŸ§  AI Capabilities

- **Query Enhancement**: HyDE, expansion, decomposition
- **Context Resolution**: Smart document ranking
- **Conversation Memory**: Persistent chat history
- **Multi-Query Processing**: Parallel query execution
- **Semantic Chunking**: Intelligent text splitting
- **Cross-Encoder Re-ranking**: Advanced result scoring

### âš¡ Performance Features

- **Async Processing**: Non-blocking operations
- **Smart Caching**: LRU cache for embeddings and queries
- **Incremental Updates**: Only process changed files
- **Background Processing**: System tray monitoring
- **Resource Management**: Memory and CPU optimization

## ğŸ” Troubleshooting

### Common Issues

#### ğŸ”§ **Ollama Connection Issues**
```bash
# Start Ollama service
ollama serve

# Check if models are available
ollama list

# Pull required models
ollama pull mistral:latest
ollama pull nomic-embed-text:latest
```

#### ğŸ“ **Import/Module Errors**
```bash
# Ensure proper installation
pip install -e .

# Check Python path
python -c "import sys; print('\n'.join(sys.path))"

# Verify core modules
python -c "from core.rag.query import query_knowledgebase; print('âœ… Imports OK')"
```

#### ğŸ’¾ **Memory Issues**
```bash
# Reduce chunk size for large documents
export ORION_CHUNK_SIZE=500

# Limit concurrent processing
export ORION_MAX_WORKERS=2

# Enable incremental processing
export ORION_ASYNC_PROCESSING=false
```

#### ğŸ” **Empty Query Results**
- Check if documents were properly ingested
- Verify vectorstore path exists
- Try increasing retrieval count (`-k 10`)
- Test with simpler queries first

### Performance Optimization

#### ğŸ“ˆ **For Better Speed**
```bash
# Enable async processing
export ORION_ASYNC_PROCESSING=true

# Increase cache size
export ORION_CACHE_SIZE=2000

# Use faster embedding model
export ORION_EMBEDDING_MODEL="all-MiniLM-L6-v2"
```

#### ğŸ¯ **For Better Accuracy**
```bash
# Use larger chunks for context
export ORION_CHUNK_SIZE=1500
export ORION_CHUNK_OVERLAP=300

# Increase retrieval documents
export ORION_RETRIEVAL_K=8

# Enable query enhancement
export ORION_QUERY_ENHANCEMENT=true
```

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### Development Workflow

```bash
# Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/Orion.git
cd Orion

# Create a feature branch
git checkout -b feature/amazing-feature

# Install development dependencies
pip install -r requirements-dev.txt

# Make your changes and add tests
pytest tests/

# Ensure code quality
black . && ruff check --fix .

# Commit and push
git commit -m "Add amazing feature"
git push origin feature/amazing-feature
```

### Contribution Guidelines

- **ğŸ§ª Tests Required**: All new features need tests
- **ğŸ“ Documentation**: Update README for significant changes  
- **ğŸ¨ Code Style**: Follow Black + Ruff formatting
- **ğŸ” Type Hints**: Use type annotations
- **ğŸ“‹ Commit Messages**: Clear, descriptive commits

### Areas for Contribution

- ğŸŒ **Frontend Development**: Svelte UI components
- ğŸ“± **Desktop Integration**: Tauri app features
- ğŸ§  **AI Enhancements**: New query processing techniques
- ğŸ“„ **Document Processing**: Support for new file formats
- ğŸ”§ **Performance**: Optimization and caching improvements

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

### Core Technologies
- **[Ollama](https://ollama.ai)** - Local LLM hosting and management
- **[LangChain](https://langchain.com)** - RAG framework and components
- **[FastAPI](https://fastapi.tiangolo.com)** - Modern web API framework
- **[FAISS](https://github.com/facebookresearch/faiss)** - Efficient similarity search

### Development Tools  
- **[Pytest](https://pytest.org)** - Testing framework
- **[Black](https://github.com/psf/black)** - Code formatting
- **[Ruff](https://github.com/astral-sh/ruff)** - Fast Python linting
- **[Rich](https://github.com/Textualize/rich)** - Beautiful terminal output

### UI & Integration
- **[Svelte](https://svelte.dev)** - Frontend framework
- **[Tauri](https://tauri.app)** - Desktop application framework
- **[PyStray](https://github.com/moses-palmer/pystray)** - System tray integration

---

<div align="center">

**â­ Star this repository if you find it helpful!**

[Report Bug](https://github.com/Ralf090102/Orion/issues) â€¢ [Request Feature](https://github.com/Ralf090102/Orion/issues) â€¢ [Contribute](https://github.com/Ralf090102/Orion/pulls)

</div>
